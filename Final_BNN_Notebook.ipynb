{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_BNN_Notebook.ipynb","provenance":[{"file_id":"1QAWRlEJ4gr2LS3haZUfVbbbuE7afT0BF","timestamp":1649885698260}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0jFbECtDId-","executionInfo":{"status":"ok","timestamp":1650489352734,"user_tz":240,"elapsed":3279,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"ef3ef7b7-a6b9-429c-d2d3-4e75defb88a3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.16.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"piSBrNP-kvxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650489357306,"user_tz":240,"elapsed":4577,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"d1b3061f-1607-4dd7-9ebb-6a19333a54ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import matplotlib.pyplot as plt\n","import os\n","import argparse\n","import matplotlib\n","# importing required libraries\n","import tensorflow as tf \n","import tensorflow_addons as tfa\n","import numpy as np\n","import pandas as pd\n","import os\n","import cv2\n","from skimage import color\n","import scipy\n","import math\n","\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","\n","import keras\n","from keras import callbacks\n","from keras import optimizers\n","#from keras.engine import Model\n","from keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n","from keras.utils.np_utils import to_categorical\n","from keras.models import Sequential\n","from keras.callbacks import ModelCheckpoint\n","\n","from keras.preprocessing import image\n","from keras.applications.vgg16 import preprocess_input\n","from keras.applications.vgg16 import decode_predictions\n","\n","from google.colab import drive\n","from google.colab.patches import cv2_imshow\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from Adam import Adam_Metaplastic\n","from data_utils import *\n","from BNN_Conv import *"],"metadata":{"id":"08mvODdekz5m","executionInfo":{"status":"ok","timestamp":1650489357595,"user_tz":240,"elapsed":292,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def rescale(i, image, width, height):\n","  new_im = cv2.resize(image,(width,height))\n","  return new_im"],"metadata":{"id":"Q6WCVi5bCqDk","executionInfo":{"status":"ok","timestamp":1650489357596,"user_tz":240,"elapsed":8,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# FOR INITIAL RAW IMAGES\n","faulty_dir = '/content/drive/Shareddrives/Senior Thesis/Casting_image/casting_512x512/casting_512x512/def_front/'\n","ok_dir = '/content/drive/Shareddrives/Senior Thesis/Casting_image/casting_512x512/casting_512x512/ok_front/'\n","\n","# FOR AUGMENTED IMAGES\n","#faulty_dir = '/content/drive/Shareddrives/Senior Thesis/Casting_image/casting_data/casting_data/images/def_front/'\n","#ok_dir = '/content/drive/Shareddrives/Senior Thesis/Casting_image/casting_data/casting_data/images/ok_front/'\n","directories = (faulty_dir, ok_dir)\n","\n","# check the total number of images we have\n","count = 0\n","for direct in directories:\n","  for file in os.listdir(direct):\n","    count += 1\n","\n","# set the values of the X and y arrays\n","num_images = count\n","dim = 100\n","input_shape = (dim, dim, 3)\n","height = input_shape[0]\n","width = input_shape[1]\n","channels = input_shape[2]\n","\n","X = np.zeros((num_images,height,width,channels))\n","y = np.zeros((num_images))\n","\n","# populate the arrays\n","i = 0\n","j = -1\n","for direct in directories:\n","  j+=1\n","  for file in os.listdir(direct):\n","    #print(file)\n","    path = (direct+file)\n","    im = plt.imread(path)\n","    scaled_im = rescale(i, im, width, height)\n","    #edges, gradient = filter(scaled_im[:,:,0])\n","    X[i] = scaled_im\n","    if j == 0:\n","      # 1 for faulty\n","      y[i] = 1\n","    else:\n","      # 0 for ok image\n","      y[i] = 0\n","    i+=1"],"metadata":{"id":"YzQDkE6TCxxY","executionInfo":{"status":"ok","timestamp":1650489366560,"user_tz":240,"elapsed":8968,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","dims = 50\n","X_train = X\n","y_train = y\n","X_train_fit = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]*X_train.shape[3])\n","pca = PCA(0.99)\n","X_train_fit = pca.fit_transform(X_train_fit)\n","#kmeans clustering on PCA data\n","from sklearn.cluster import AgglomerativeClustering\n","data = AgglomerativeClustering(n_clusters = 3, compute_distances=True).fit(X_train_fit)"],"metadata":{"id":"c9dDsbNlCTtq","executionInfo":{"status":"ok","timestamp":1650489377811,"user_tz":240,"elapsed":11265,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# import tensorflow as tf\n","# MyModel = tf.keras.models.Sequential()\n","# MyModel.add(tf.keras.applications.ResNet50(include_top = False, weights='imagenet', pooling='avg',))\n","# MyModel.layers[0].trainable = False\n","# img = tf.keras.applications.resnet50.preprocess_input(X_train)\n","# extractedFeatures = MyModel.predict(img)\n","# pca_processed = PCA(0.99)\n","# X_processed = pca_processed.fit_transform(extractedFeatures)\n","# data_processed = AgglomerativeClustering(n_clusters = 3, compute_distances=True).fit(X_processed)"],"metadata":{"id":"daFg2hzdVwNW","executionInfo":{"status":"ok","timestamp":1650489377811,"user_tz":240,"elapsed":13,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["path_name = \"/content/drive/Shareddrives/Senior Thesis/Models/my_model_1__forSegmentation_100.hdf5\"\n","segModel = tf.keras.models.load_model(path_name)\n","last = segModel.layers[-2].output\n","fullmodel = tf.keras.Model(segModel.input, last)\n","fullmodel.summary()\n","extractedFeatures = fullmodel.predict(X_train)\n","pca_processed = PCA(n_components = 50)\n","X_processed = pca_processed.fit_transform(extractedFeatures)\n","data_processed = AgglomerativeClustering(n_clusters = 3, compute_distances=True).fit(X_processed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OLH0r0Ro_cW","executionInfo":{"status":"ok","timestamp":1650489385013,"user_tz":240,"elapsed":7214,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"c55d50c2-0358-41e6-ab4c-0e13a365ad4a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 4608)              0         \n","                                                                 \n"," fc1 (Dense)                 (None, 1000)              4609000   \n","                                                                 \n"," dropout (Dropout)           (None, 1000)              0         \n","                                                                 \n","=================================================================\n","Total params: 19,323,688\n","Trainable params: 4,609,000\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from mpl_toolkits import mplot3d\n","%matplotlib inline\n","import matplotlib"],"metadata":{"id":"ft4NZ4OIHFqe","executionInfo":{"status":"ok","timestamp":1650489385014,"user_tz":240,"elapsed":28,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["idx_train0 = np.array(np.where(y_train==0)).flatten()\n","idx_train1 = np.array(np.where(y_train==1)).flatten()\n","idx_labels0 = np.array(np.where(data_processed.labels_==0)).flatten()\n","idx_labels1 = np.array(np.where(data_processed.labels_==1)).flatten()\n","idx_labels2 = np.array(np.where(data_processed.labels_==2)).flatten()\n","\n","mapping = np.zeros((2,3))\n","\n","mapping[0,0] = len(np.intersect1d(idx_train0, idx_labels0))\n","mapping[0,1] = len(np.intersect1d(idx_train0, idx_labels1))\n","mapping[0,2] = len(np.intersect1d(idx_train0, idx_labels2))\n","\n","mapping[1,0] = len(np.intersect1d(idx_train1, idx_labels0))\n","mapping[1,1] = len(np.intersect1d(idx_train1, idx_labels1))\n","mapping[1,2] = len(np.intersect1d(idx_train1, idx_labels2))\n","\n","print(mapping)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1A8azhdCHKTG","executionInfo":{"status":"ok","timestamp":1650489385014,"user_tz":240,"elapsed":27,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"a48bedc4-78ee-480c-9bfe-d1bd770eaa05"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[[154. 280.  85.]\n"," [431. 146. 204.]]\n"]}]},{"cell_type":"code","source":["y[np.intersect1d(idx_train1, idx_labels0)] = 1 #defective type 1\n","y[np.intersect1d(idx_train1, idx_labels2)] = 2 #defective type 2\n","print(np.array(np.where(y==0)).flatten().shape)\n","print(np.array(np.where(y==1)).flatten().shape)\n","print(np.array(np.where(y==2)).flatten().shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TtqiEG5yQUqr","executionInfo":{"status":"ok","timestamp":1650489385015,"user_tz":240,"elapsed":24,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"26283cab-d810-4a9c-dc4c-de1dd188f7aa"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["(519,)\n","(577,)\n","(204,)\n"]}]},{"cell_type":"code","source":["X_normal = X[np.where(y==0)]\n","y_normal = y[np.where(y==0)]\n","y_def1 = y[np.where(y==1)]\n","X_def1 = X[np.where(y==1)]\n","y_def2 = y[np.where(y==2)]\n","X_def2 = X[np.where(y==2)]"],"metadata":{"id":"dGHB2iXfM8uf","executionInfo":{"status":"ok","timestamp":1650489385148,"user_tz":240,"elapsed":153,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["norm_data = len(X_normal)\n","def1_data = len(X_def1)\n","def2_data = len(X_def2)"],"metadata":{"id":"dOnL2pV0PApo","executionInfo":{"status":"ok","timestamp":1650489385148,"user_tz":240,"elapsed":16,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["X_task1 = np.concatenate((X_normal, X_def1[0:norm_data]))\n","y_task1 = np.concatenate((y_normal, y_def1[0:norm_data]))\n","X_task2 = np.concatenate((X_normal[0:def2_data], X_def2))\n","y_task2 = np.concatenate((y_normal[0:def2_data], y_def2))\n","y_task2[np.where(y_task2==2)] = 1\n","\n","print(X_task1.shape)\n","print(y_task1.shape)\n","print(X_task2.shape)\n","print(y_task2.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9-af_R8NmwP","executionInfo":{"status":"ok","timestamp":1650489385372,"user_tz":240,"elapsed":123,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"e302694c-37ec-49b3-e058-83773ee808fe"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(1038, 100, 100, 3)\n","(1038,)\n","(408, 100, 100, 3)\n","(408,)\n"]}]},{"cell_type":"code","source":["from keras.utils.np_utils import to_categorical\n","y_task1_cat = to_categorical(y_task1)\n","y_task2_cat = to_categorical(y_task2)\n","print(y_task1_cat.shape)\n","print(y_task2_cat.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ez1EERE9RZh","executionInfo":{"status":"ok","timestamp":1650489385373,"user_tz":240,"elapsed":7,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"30886e79-4878-4022-a8f2-ef3663cf9d61"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["(1038, 2)\n","(408, 2)\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","frac = 0.3\n","\n","X_task1_train, X_task1_test, y_task1_train, y_task1_test = train_test_split(X_task1, y_task1_cat, test_size = frac, random_state=1)\n","X_task2_train, X_task2_test, y_task2_train, y_task2_test  = train_test_split(X_task2, y_task2_cat, test_size = frac, random_state=1)\n","print(X_task1_train.shape)\n","print(X_task2_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6LQNEImvyHT","executionInfo":{"status":"ok","timestamp":1650489385454,"user_tz":240,"elapsed":85,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"c6794915-b1ee-4eb6-ead8-ff388a255b09"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(726, 100, 100, 3)\n","(285, 100, 100, 3)\n"]}]},{"cell_type":"code","source":["class CustomImageDataset(torch.utils.data.Dataset):\n","  def __init__(self, images, labels):\n","          self.labels = labels\n","          self.images = images\n","  def __len__(self):\n","          return len(self.labels)\n","  def __getitem__(self, idx):\n","          label = self.labels[idx]\n","          image = self.images[idx]\n","          sample = {'image': image, 'label': label}\n","          return sample"],"metadata":{"id":"4SQy-Ue61-eD","executionInfo":{"status":"ok","timestamp":1650489385455,"user_tz":240,"elapsed":5,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["X_train = torch.Tensor(np.transpose(X_task1_train,(0,3,1,2)))\n","X_test = torch.Tensor(np.transpose(X_task1_test,(0,3,1,2)))\n","print(X_train.shape)\n","print(X_test.shape)\n","train_data = CustomImageDataset(X_train,y_task1_train)\n","test_data = CustomImageDataset(X_test,y_task1_test)\n","train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n","test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FExpqNBivU5I","executionInfo":{"status":"ok","timestamp":1650489385455,"user_tz":240,"elapsed":4,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"ce5cfe1c-6c2f-4a09-b63f-de515bdcd723"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([726, 3, 100, 100])\n","torch.Size([312, 3, 100, 100])\n"]}]},{"cell_type":"markdown","source":["**Normal Model**"],"metadata":{"id":"EUmZlYCpNDQY"}},{"cell_type":"code","source":["import torch.nn as nn\n","class CNN(nn.Module):\n","    def __init__(self, width = 0.01, norm = 'batch'):\n","        super(CNN, self).__init__()\n","\n","        self.hidden_layers = 2\n","\n","        # modeled from example_model_initialization in COS429 Student Assignment 3 - Master\n","        # define network topology\n","        conv1 = nn.Conv2d(3, 32, kernel_size=5, padding = 2, stride = 2, bias=False)\n","        norm1 = self.normalization(32,2,norm)\n","        conv2 = nn.Conv2d(32, 64, kernel_size=4, padding = 2, stride =2, bias=False)\n","        norm2 = self.normalization(64,2,norm)\n","        linear = nn.Linear(43264,3, bias=False)\n","        norm3 = self.normalization(3,1,norm)\n","        act3 = nn.Softmax(dim=0)\n","\n","        # pytorch ModuleDict https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html\n","        self.layers = nn.ModuleDict({'cv1': conv1, 'n1': norm1, 'cv2': conv2, 'n2': norm2, 'fc':linear, 'n3':norm3, 'a3':act3})\n","\n","        # initialize weights\n","        # from pytorch init documentation https://pytorch.org/docs/stable/nn.init.html\n","        nn.init.normal_(conv1.weight, mean=0, std=width)\n","        nn.init.normal_(conv2.weight, mean=0, std=width)\n","        nn.init.normal_(linear.weight, mean=0, std=width)\n","          \n","    def normalization(self, size, dim, norm):\n","        # from pytorch documentation: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html\n","        if norm == 'batch':\n","            if dim==2:\n","                return nn.BatchNorm2d(size, affine=True, track_running_stats=True)\n","            else:\n","                return nn.BatchNorm1d(size, affine=True, track_running_stats=True)\n","        else:\n","            if dim==2:\n","                return nn.InstanceNorm2d(size, affine=False, track_running_stats=False)\n","            else:\n","                return nn.InstanceNorm1d(size, affine=False, track_running_stats=False)\n","\n","    def forward(self, x):\n","        x = self.layers['cv1'](x)\n","        x = self.layers['n1'](x)\n","\n","        x = self.layers['cv2'](x)\n","        x = self.layers['n2'](x)\n","\n","        # flatten x before the fully connected layer via pytorch's view function\n","        x = x.view(x.size(0), -1)\n","        x = self.layers['fc'](x)\n","        x = self.layers['n3'](x)\n","        x = self.layers['a3'](x)\n","\n","        return x\n","        "],"metadata":{"id":"MgwdlDudNBae","executionInfo":{"status":"ok","timestamp":1650489385540,"user_tz":240,"elapsed":4,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["### Hyperparameters"],"metadata":{"id":"myVVUWsmlPCH"}},{"cell_type":"code","source":["# Hyperparameters\n","lr = 0.005\n","epochs = 10\n","meta = 1.35\n","\n","#init = \"normal\"\n","init_width = 0.1\n","decay = 0\n","gamma = 1\n","norm = 'batch'\n","lrs = [lr*(gamma**(-i)) for i in range(epochs)]"],"metadata":{"id":"U_UuvYbplOVB","executionInfo":{"status":"ok","timestamp":1650490030756,"user_tz":240,"elapsed":117,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["## Define Model"],"metadata":{"id":"Fj5Tt_8HlT53"}},{"cell_type":"code","source":["model = ConvNet(width = init_width)"],"metadata":{"id":"7W4o4Ba-lU7o","executionInfo":{"status":"ok","timestamp":1650489385640,"user_tz":240,"elapsed":103,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Train and Test Functions\n"],"metadata":{"id":"Apb8gxdhlnC0"}},{"cell_type":"code","source":["def train(model, train_loader, optimizer, batch_size, criterion = torch.nn.CrossEntropyLoss()):\n","    \n","    model.train()\n","\n","    target = np.zeros((batch_size,2))\n","    data = np.zeros((batch_size,3,100,100))\n","\n","    for i in range(batch_size):\n","      target[i,:]  = next(iter(train_loader))['label']\n","      data[i,:,:,:] = next(iter(train_loader))['image']\n","\n","    target = torch.Tensor(target)\n","    data = torch.Tensor(data)\n","\n","    optimizer.zero_grad()\n","    output = model.forward(data)\n","    loss = criterion(output, target)\n","    loss.backward() \n","    optimizer.step()"],"metadata":{"id":"FLJiS8pTlks0","executionInfo":{"status":"ok","timestamp":1650489385641,"user_tz":240,"elapsed":3,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def test(model, test_loader, batch_size, criterion = torch.nn.CrossEntropyLoss(reduction='sum'), verbose = False):\n","    \n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    \n","    target = np.zeros((batch_size,2))\n","    data = np.zeros((batch_size,3,100,100))\n","\n","    for i in range(batch_size):\n","      target[i,:]  = next(iter(test_loader))['label']\n","      data[i,:,:,:] = next(iter(test_loader))['image']\n","    \n","    target = torch.Tensor(target)\n","    data = torch.Tensor(data)\n","\n","    output = model.forward(data)\n","    test_loss = criterion(output, target).item() # mean batch loss\n","    pred = output.max(1, keepdim=True)[1].flatten() # get the index of the max log-probability\n","    target_label = target.max(1, keepdim=True)[1].flatten()\n","    correct = torch.eq(target_label, pred).sum()\n","\n","    test_loss /= batch_size\n","    test_acc = 100 * correct / batch_size\n","    \n","    print('Test accuracy: ', (correct, test_acc))\n","\n","    return test_acc, test_loss"],"metadata":{"id":"zlB9rTo5luvZ","executionInfo":{"status":"ok","timestamp":1650489385641,"user_tz":240,"elapsed":3,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## Run Model"],"metadata":{"id":"zhwWhZPBl0u8"}},{"cell_type":"code","source":["optimizer = Adam_Metaplastic(model.parameters(), lr = 0.005, meta = meta, weight_decay = decay)\n","        \n","for epoch in range(1, epochs+1):\n","  train(model, train_data_loader, optimizer, batch_size = 128)\n","\n","  print(f\"EPOCH: {epoch}\")\n","  test_accuracy, test_loss = test(model, test_data_loader, batch_size = 64)\n","  \n","  #current_bn_state = model.save_bn_states()\n","  #test_accuracy, test_loss = test(model, other_task, verbose=True)"],"metadata":{"id":"6kMSNIcNl1mC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650490036870,"user_tz":240,"elapsed":4018,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}},"outputId":"066a1183-a379-4ca8-bab2-0cd5aa1397e1"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/BNN_Conv.py:125: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  x = self.layers['a3'](x)\n"]},{"output_type":"stream","name":"stdout","text":["EPOCH: 1\n","Test accuracy:  (tensor(25), tensor(39.0625))\n","EPOCH: 2\n","Test accuracy:  (tensor(32), tensor(50.))\n","EPOCH: 3\n","Test accuracy:  (tensor(34), tensor(53.1250))\n","EPOCH: 4\n","Test accuracy:  (tensor(30), tensor(46.8750))\n","EPOCH: 5\n","Test accuracy:  (tensor(36), tensor(56.2500))\n","EPOCH: 6\n","Test accuracy:  (tensor(28), tensor(43.7500))\n","EPOCH: 7\n","Test accuracy:  (tensor(33), tensor(51.5625))\n","EPOCH: 8\n","Test accuracy:  (tensor(36), tensor(56.2500))\n","EPOCH: 9\n","Test accuracy:  (tensor(32), tensor(50.))\n","EPOCH: 10\n","Test accuracy:  (tensor(36), tensor(56.2500))\n"]}]},{"cell_type":"code","source":["from keras.applications.vgg16 import VGG16\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n","# We freeze every layer in our base model so that they do not train, we want that our feature extractor stays as before --> transfer learning\n","for layer in base_model.layers: \n","  layer.trainable = False\n","  print('Layer ' + layer.name + ' frozen.')\n","# We take the last layer of our the model and add it to our classifier\n","last = base_model.layers[-1].output\n","x = Flatten()(last)\n","x = Dense(1000, activation='relu', name='fc1')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(2, activation='softmax', name='predictions')(x)\n","model = tf.keras.Model(base_model.input, x)\n","\n","# We compile the model\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n","loss_entropy = tf.keras.losses.CategoricalCrossentropy()\n","loss_binary_entropy = tf.keras.losses.BinaryCrossentropy()\n","model.compile(optimizer=optimizer, loss=loss_entropy, metrics=['accuracy'])\n","from keras.utils.vis_utils import plot_model\n","#plot_model(model, to_file='classifier_plot.png', show_shapes=True, show_layer_names=True)"],"metadata":{"id":"NnbJfAxPMZd_","executionInfo":{"status":"aborted","timestamp":1650489544048,"user_tz":240,"elapsed":7,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We start the training\n","#tf.config.experimental_run_functions_eagerly(True)\n","config = 1\n","transform = \"2class_sequential\"\n","preprocess = \"\"\n","imsize = str(dim)\n","path_name = f\"{'/content/drive/Shareddrives/Senior Thesis/Models/my_model_'}{config}{'_'}{preprocess}{'_'}{transform}{'_'}{imsize}{'.hdf5'}\"\n","earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n","mcp_save = tf.keras.callbacks.ModelCheckpoint(path_name, save_best_only=True, monitor='val_loss', mode='min')\n","reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, min_delta=1e-4, mode='min')"],"metadata":{"id":"osNLTF6EMh8a","executionInfo":{"status":"aborted","timestamp":1650489544056,"user_tz":240,"elapsed":15,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_accuracy = []\n","other_val_accuracy = []\n","for i in range(20):\n","  model.fit(x=X_task2_train, y=y_task2_train, batch_size=64, epochs=1, verbose=1, callbacks=[mcp_save, reduce_lr_loss], validation_data=(X_task2_test,y_task2_test), shuffle=True)\n","  other_val_accuracy.append(model.history.history['val_accuracy'])\n","  loss, acc  = model.evaluate(X_task1_test, y_task1_test)\n","  val_accuracy.append(acc)\n","for i in range(20):\n","  model.fit(x=X_task1_train, y=y_task1_train, batch_size=64, epochs=1, verbose=1, callbacks=[mcp_save, reduce_lr_loss], validation_data=(X_task1_test,y_task1_test), shuffle=True)\n","  val_accuracy.append(model.history.history['val_accuracy'])\n","  loss, acc  = model.evaluate(X_task2_test, y_task2_test)\n","  other_val_accuracy.append(acc)"],"metadata":{"id":"RBzXFyjbMGZd","executionInfo":{"status":"aborted","timestamp":1650489544057,"user_tz":240,"elapsed":16,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["task1 = np.zeros((40))\n","task2 = np.zeros((40))\n","for i in range(len(val_accuracy)):\n","  if type(val_accuracy[i]) == list:\n","    task1[i] = val_accuracy[i][0]\n","  else:\n","    task1[i] = val_accuracy[i]\n","\n","for i in range(len(other_val_accuracy)):\n","  if type(other_val_accuracy[i]) == list:\n","    task2[i] = other_val_accuracy[i][0]\n","  else:\n","    task2[i] = other_val_accuracy[i]"],"metadata":{"id":"HOJ968CuQL6o","executionInfo":{"status":"aborted","timestamp":1650489544057,"user_tz":240,"elapsed":15,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accuracy = model.history.history['accuracy']\n","# val_accuracy = model.history.history['val_accuracy']\n","# loss = model.history.history['loss']\n","# val_loss = model.history.history['val_loss']"],"metadata":{"id":"9JDAOjYKMqui","executionInfo":{"status":"aborted","timestamp":1650489544057,"user_tz":240,"elapsed":15,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","data = np.zeros((40,2))\n","data[:,0] = task1\n","data[:,1] = task2\n","#data[:N,2] = loss\n","#data[:N,3] = val_loss\n","\n","df = pd.DataFrame(data)\n","df.to_excel(excel_writer = \"/content/data.xlsx\")"],"metadata":{"id":"lR2yXX4hMu2w","executionInfo":{"status":"aborted","timestamp":1650489544058,"user_tz":240,"elapsed":16,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","start = time.time()\n","model.predict(X)\n","print((time.time()-start)/len(X))"],"metadata":{"id":"A6G7aB9kMzQU","executionInfo":{"status":"aborted","timestamp":1650489544058,"user_tz":240,"elapsed":16,"user":{"displayName":"Pranav Iyer","userId":"02870766238855931983"}}},"execution_count":null,"outputs":[]}]}